{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Embedding, LSTM, RepeatVector\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import re\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404290\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in share market in india?</td>\n",
       "      <td>What is the step by step guide to invest in share market?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Diamond?</td>\n",
       "      <td>What would happen if the Indian government stole the Kohinoor (Koh-i-Noor) diamond back?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet connection while using a VPN?</td>\n",
       "      <td>How can Internet speed be increased by hacking through DNS?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve it?</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] is divided by 24,23?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt, methane and carbon di oxide?</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2  \\\n",
       "0  0   1     2      \n",
       "1  1   3     4      \n",
       "2  2   5     6      \n",
       "3  3   7     8      \n",
       "4  4   9     10     \n",
       "\n",
       "                                                                      question1  \\\n",
       "0  What is the step by step guide to invest in share market in india?             \n",
       "1  What is the story of Kohinoor (Koh-i-Noor) Diamond?                            \n",
       "2  How can I increase the speed of my internet connection while using a VPN?      \n",
       "3  Why am I mentally very lonely? How can I solve it?                             \n",
       "4  Which one dissolve in water quikly sugar, salt, methane and carbon di oxide?   \n",
       "\n",
       "                                                                                  question2  \\\n",
       "0  What is the step by step guide to invest in share market?                                  \n",
       "1  What would happen if the Indian government stole the Kohinoor (Koh-i-Noor) diamond back?   \n",
       "2  How can Internet speed be increased by hacking through DNS?                                \n",
       "3  Find the remainder when [math]23^{24}[/math] is divided by 24,23?                          \n",
       "4  Which fish would survive in salt water?                                                    \n",
       "\n",
       "   is_duplicate  \n",
       "0  0             \n",
       "1  0             \n",
       "2  0             \n",
       "3  0             \n",
       "4  0             "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.csv.zip\", sep=\",\", compression=\"zip\")\n",
    "print(len(train_df))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Cleaning the corpus and getting word2vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopwords = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "stopwords = stopwords.difference(set([\"can\", \"who\", \"any\", \"which\", \"when\", \"whom\", \n",
    "                                      \"if\", \"what\", \"how\", \"why\", \"where\", \"only\", \"same\", \"more\", \"now\"\n",
    "                                     ]))\n",
    "\n",
    "def process_question(raw_question):\n",
    "    tokens = re.sub(r\"[^a-z0-9]+\", \" \", str(raw_question).lower()).split()\n",
    "    return [x for x in tokens if x not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537933\n",
      "[['what', 'step', 'step', 'guide', 'invest', 'share', 'market', 'india'], ['what', 'step', 'step', 'guide', 'invest', 'share', 'market'], ['what', 'story', 'kohinoor', 'koh', 'noor', 'diamond'], ['what', 'would', 'happen', 'if', 'indian', 'government', 'stole', 'kohinoor', 'koh', 'noor', 'diamond', 'back'], ['how', 'can', 'increase', 'speed', 'internet', 'connection', 'using', 'vpn'], ['how', 'can', 'internet', 'speed', 'increased', 'hacking', 'dns'], ['why', 'mentally', 'lonely', 'how', 'can', 'solve'], ['find', 'remainder', 'when', 'math', '23', '24', 'math', 'divided', '24', '23'], ['which', 'one', 'dissolve', 'water', 'quikly', 'sugar', 'salt', 'methane', 'carbon', 'di', 'oxide'], ['which', 'fish', 'would', 'survive', 'salt', 'water']]\n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "seen_ids = set()\n",
    "\n",
    "for index, row in train_df.iterrows():\n",
    "    q1_id = row[\"qid1\"]\n",
    "    if q1_id not in seen_ids:\n",
    "        corpus.append(process_question(row[\"question1\"]))\n",
    "        seen_ids.add(q1_id)\n",
    "    q2_id = row[\"qid2\"]\n",
    "    if q2_id not in seen_ids:\n",
    "        corpus.append(process_question(row[\"question2\"]))\n",
    "        seen_ids.add(q2_id)    \n",
    "        \n",
    "print(len(corpus))\n",
    "print(corpus[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_embeddings = Word2Vec(corpus, size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('xat', 0.7255841493606567),\n",
       " ('gmat', 0.6986239552497864),\n",
       " ('percentile', 0.6843202114105225),\n",
       " ('toefl', 0.6835753321647644),\n",
       " ('bitsat', 0.6814593076705933),\n",
       " ('aipmt', 0.6771522760391235),\n",
       " ('clat', 0.6725986003875732),\n",
       " ('cmat', 0.6654667854309082),\n",
       " ('gre', 0.6620069146156311),\n",
       " ('aiims', 0.6526833176612854)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_embeddings.most_similar(positive=[\"cat\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85180\n",
      "108\n"
     ]
    }
   ],
   "source": [
    "word2index_map = {}\n",
    "index2word_map = {}\n",
    "max_question_length = 0\n",
    "current_index = 1\n",
    "\n",
    "for index, row in train_df.iterrows():\n",
    "    tokens_a = process_question(row[\"question1\"])\n",
    "    tokens_b = process_question(row[\"question2\"])\n",
    "    max_question_length = max(max_question_length, max(len(tokens_a), len(tokens_b)))\n",
    "    for token in tokens_a + tokens_b:\n",
    "        if token not in word2index_map:\n",
    "            word2index_map[token] = current_index\n",
    "            index2word_map[current_index] = token\n",
    "            current_index += 1\n",
    "            \n",
    "print(len(word2index_map))\n",
    "print(max_question_length)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(index2word_map) + 1, 100))\n",
    "for i in range(1, len(index2word_map) + 1):\n",
    "    if index2word_map[i] in w2v_embeddings:\n",
    "        embedding_matrix[i, :] = w2v_embeddings[index2word_map[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(input_dim=len(index2word_map)+1,\n",
    "                            output_dim=100,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=max_question_length,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a dataset of duplicate pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149263\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?</td>\n",
       "      <td>I'm a triple Capricorn (Sun, Moon and ascendant in Capricorn) What does this say about me?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>How can I be a good geologist?</td>\n",
       "      <td>What should I do to be a great geologist?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "      <td>How do I read and find my YouTube comments?</td>\n",
       "      <td>How can I see all my Youtube comments?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>What can make Physics easy to learn?</td>\n",
       "      <td>How can you make physics easy to learn?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>What was your first sexual experience like?</td>\n",
       "      <td>What was your first sexual experience?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  id  qid1  qid2  \\\n",
       "0  5      5   11    12     \n",
       "1  7      7   15    16     \n",
       "2  11     11  23    24     \n",
       "3  12     12  25    26     \n",
       "4  13     13  27    28     \n",
       "\n",
       "                                                                                question1  \\\n",
       "0  Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?   \n",
       "1  How can I be a good geologist?                                                           \n",
       "2  How do I read and find my YouTube comments?                                              \n",
       "3  What can make Physics easy to learn?                                                     \n",
       "4  What was your first sexual experience like?                                              \n",
       "\n",
       "                                                                                    question2  \\\n",
       "0  I'm a triple Capricorn (Sun, Moon and ascendant in Capricorn) What does this say about me?   \n",
       "1  What should I do to be a great geologist?                                                    \n",
       "2  How can I see all my Youtube comments?                                                       \n",
       "3  How can you make physics easy to learn?                                                      \n",
       "4  What was your first sexual experience?                                                       \n",
       "\n",
       "   is_duplicate  \n",
       "0  1             \n",
       "1  1             \n",
       "2  1             \n",
       "3  1             \n",
       "4  1             "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates = train_df[train_df[\"is_duplicate\"] == 1].reset_index()\n",
    "duplicate_pairs_num = len(duplicates)\n",
    "print(duplicate_pairs_num)\n",
    "duplicates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "duplicates_left = np.zeros((duplicate_pairs_num, max_question_length))\n",
    "duplicates_right = np.zeros((duplicate_pairs_num, max_question_length))\n",
    "\n",
    "for index, row in duplicates.iterrows():\n",
    "    token_left = process_question(row[\"question1\"])\n",
    "    indices_left = [word2index_map[token] for token in token_left]\n",
    "    duplicates_left[index, :] = pad_sequences([indices_left], maxlen=max_question_length)\n",
    "    \n",
    "    token_right = process_question(row[\"question2\"])\n",
    "    indices_right = [word2index_map[token] for token in token_right]\n",
    "    duplicates_right[index, :] = pad_sequences([indices_right], maxlen=max_question_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Keras encoder-decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder_model = Sequential()\n",
    "encoder_model.add(embedding_layer)\n",
    "encoder_model.add(LSTM(output_dim=100, input_dim=100, input_length=max_question_length, return_sequences=False))\n",
    "encoder_model.add(RepeatVector(max_question_length))\n",
    "encoder_model.add(LSTM(input_dim=100, output_dim=100, return_sequences=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some helpful links:\n",
    "* https://github.com/fchollet/keras/issues/369\n",
    "* http://stackoverflow.com/questions/42253934/keras-how-to-use-the-learned-embedding-layer-for-input-and-output\n",
    "* https://keras.io/layers/recurrent/\n",
    "* http://stackoverflow.com/questions/42140922/keras-lstm-training-data-format?rq=1\n",
    "* https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html\n",
    "* http://stackoverflow.com/questions/38134379/keras-sequence-to-sequence-encoder-decoder-part-of-speech-tagging-example-with-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Bad input argument to theano function with name \"C:\\Users\\lyapin roman\\Anaconda2\\envs\\dl_env\\lib\\site-packages\\keras\\backend\\theano_backend.py:955\" at index 1 (0-based).  \nBacktrace when that variable is created:\n\n  File \"C:\\Users\\lyapin roman\\Anaconda2\\envs\\dl_env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\lyapin roman\\Anaconda2\\envs\\dl_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\lyapin roman\\Anaconda2\\envs\\dl_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\lyapin roman\\Anaconda2\\envs\\dl_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-59-54b60236f0d2>\", line 3, in <module>\n    encoder_model.compile(loss=custom_loss, optimizer=\"adam\")\n  File \"C:\\Users\\lyapin roman\\Anaconda2\\envs\\dl_env\\lib\\site-packages\\keras\\models.py\", line 594, in compile\n    **kwargs)\n  File \"C:\\Users\\lyapin roman\\Anaconda2\\envs\\dl_env\\lib\\site-packages\\keras\\engine\\training.py\", line 650, in compile\n    dtype=K.dtype(self.outputs[i])))\n  File \"C:\\Users\\lyapin roman\\Anaconda2\\envs\\dl_env\\lib\\site-packages\\keras\\backend\\theano_backend.py\", line 110, in placeholder\n    x = T.TensorType(dtype, broadcast)(name)\nWrong number of dimensions: expected 3, got 2 with shape (32, 108).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-54b60236f0d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedding_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mencoder_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"adam\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mencoder_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mduplicates_left\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mduplicates_right\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\lyapin roman\\Anaconda2\\envs\\dl_env\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    670\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m    673\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32mC:\\Users\\lyapin roman\\Anaconda2\\envs\\dl_env\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[0;32m   1194\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1195\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1196\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1198\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\lyapin roman\\Anaconda2\\envs\\dl_env\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[0;32m    889\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\lyapin roman\\Anaconda2\\envs\\dl_env\\lib\\site-packages\\keras\\backend\\theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    957\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 959\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    960\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\lyapin roman\\Anaconda2\\envs\\dl_env\\lib\\site-packages\\theano\\compile\\function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    793\u001b[0m                         s.storage[0] = s.type.filter(\n\u001b[0;32m    794\u001b[0m                             \u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                             allow_downcast=s.allow_downcast)\n\u001b[0m\u001b[0;32m    796\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\lyapin roman\\Anaconda2\\envs\\dl_env\\lib\\site-packages\\theano\\tensor\\type.py\u001b[0m in \u001b[0;36mfilter\u001b[1;34m(self, data, strict, allow_downcast)\u001b[0m\n\u001b[0;32m    176\u001b[0m             raise TypeError(\"Wrong number of dimensions: expected %s,\"\n\u001b[0;32m    177\u001b[0m                             \" got %s with shape %s.\" % (self.ndim, data.ndim,\n\u001b[1;32m--> 178\u001b[1;33m                                                         data.shape))\n\u001b[0m\u001b[0;32m    179\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maligned\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Bad input argument to theano function with name \"C:\\Users\\lyapin roman\\Anaconda2\\envs\\dl_env\\lib\\site-packages\\keras\\backend\\theano_backend.py:955\" at index 1 (0-based).  \nBacktrace when that variable is created:\n\n  File \"C:\\Users\\lyapin roman\\Anaconda2\\envs\\dl_env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\lyapin roman\\Anaconda2\\envs\\dl_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\lyapin roman\\Anaconda2\\envs\\dl_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\lyapin roman\\Anaconda2\\envs\\dl_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-59-54b60236f0d2>\", line 3, in <module>\n    encoder_model.compile(loss=custom_loss, optimizer=\"adam\")\n  File \"C:\\Users\\lyapin roman\\Anaconda2\\envs\\dl_env\\lib\\site-packages\\keras\\models.py\", line 594, in compile\n    **kwargs)\n  File \"C:\\Users\\lyapin roman\\Anaconda2\\envs\\dl_env\\lib\\site-packages\\keras\\engine\\training.py\", line 650, in compile\n    dtype=K.dtype(self.outputs[i])))\n  File \"C:\\Users\\lyapin roman\\Anaconda2\\envs\\dl_env\\lib\\site-packages\\keras\\backend\\theano_backend.py\", line 110, in placeholder\n    x = T.TensorType(dtype, broadcast)(name)\nWrong number of dimensions: expected 3, got 2 with shape (32, 108)."
     ]
    }
   ],
   "source": [
    "def custom_loss(y_true, y_pred):    \n",
    "    return keras.metrics.mean_squared_error(embedding_layer(y_true), y_pred)\n",
    "encoder_model.compile(loss=custom_loss, optimizer=\"adam\")\n",
    "encoder_model.fit(duplicates_left, duplicates_right, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dl_env]",
   "language": "python",
   "name": "conda-env-dl_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
